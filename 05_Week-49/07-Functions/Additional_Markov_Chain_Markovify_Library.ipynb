{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain - Markovify Library \n",
    "\n",
    "Here is the usage of a simple established library\n",
    "https://github.com/jsvine/markovify\n",
    "\n",
    "Markovify works best with large, well-punctuated texts. If your text does not use `.`s to delineate sentences, put each sentence on a newline, and use the `markovify.NewlineText` class instead of `markovify.Text` class.\n",
    "\n",
    "### So the parameters to control the result are well described there:\n",
    "\n",
    "#### `state_size`\n",
    "by changing the state_size, it's possible to train in different orders.\n",
    "\n",
    "By default, `markovify.Text` uses a state size of 2. But you can instantiate a model with a different state size. \n",
    "\n",
    "#### `tries`\n",
    "By default, the `make_sentence` method tries a maximum of 10 times per invocation, to make a sentence that does not overlap too much with the original text. If it is successful, the method returns the sentence as a string. If not, it returns `None`. To increase or decrease the number of attempts, use the `tries` keyword argument, e.g., call `.make_sentence(tries=100)`.\n",
    "\n",
    "#### `max_overlap_ratio` / `max_overlap_total`\n",
    "By default, `markovify.Text` tries to generate sentences that do not simply regurgitate chunks of the original text. The default rule is to suppress any generated sentences that exactly overlaps the original text by 15 words or 70% of the sentence's word count. You can change this rule by passing `max_overlap_ratio` and/or `max_overlap_total` to the `make_sentence` method. Alternatively, this check can be disabled entirely by passing `test_output` as False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markovify\n",
      "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 18 kB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: markovify\n",
      "  Building wheel for markovify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18610 sha256=6fbda5da6d02f3d56ef27eb0867032bbe2422948e7a55abb5f536158b6bf8384\n",
      "  Stored in directory: /Users/AprilCoffee/Library/Caches/pip/wheels/36/c5/82/11125c5a7dadec27ef49ac2b3a12d3b1f79ff7333c92a9b67b\n",
      "Successfully built markovify\n",
      "Installing collected packages: unidecode, markovify\n",
      "Successfully installed markovify-0.9.4 unidecode-1.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "\n",
    "# Get raw text as string.\n",
    "with open(\"data/MillePlateaux.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indefinite then has maximum determination: once upon a matter from a sensible intuition of variation.\n",
      "One of the war machine.\n",
      "It is well known to regulate the degree of intensity.\n",
      "Childhood scenes, children's games: the starting point is reached only in its epistrata and parastrata, with respect to justice and the opportunity to escape.\n",
      "This is in turn formalizes contents and expressions on each stratum, encasted in it, instead of positioning oneself within it.\n"
     ]
    }
   ],
   "source": [
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July 4 exactly the same way, or its universal consciousness in a lamellar or laminar flow,18 but from which no wasp-orchid can ever descend.\n",
      "The axiomatic is based on language, and music of Mozart is permeated by becomings-animal, above all that there is always a sign as information.\n",
      "Flows of intensity, introducing breaks between these strata and territories; but also in the most impor- tant role in the Altai?\n"
     ]
    }
   ],
   "source": [
    "# Print three randomly-generated sentences of no more than 280 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They thought they would perish but that is not the sum of all the invention of the faith from a formed plane of consistency.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(text_model.make_sentence(max_overlap_ratio=0.3, tries=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the order of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.Text(text, state_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Combine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning is closely tied to the mental.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to compile(train) the model\n",
    "text_model = markovify.Text(text)\n",
    "text_model = text_model.compile()\n",
    "\n",
    "with open(\"data/wiki_selection.txt\") as f:\n",
    "    text_a = f.read()\n",
    "    \n",
    "with open(\"data/alles-macht-weiter.txt\") as f:\n",
    "    text_b = f.read()\n",
    "    \n",
    "# adding and combine two different models\n",
    "model_a = markovify.Text(text_a)\n",
    "model_b = markovify.Text(text_b)\n",
    "\n",
    "model_combo = markovify.combine([ model_a, model_b ], [ 1.5, 1 ])\n",
    "model_combo.make_sentence()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
