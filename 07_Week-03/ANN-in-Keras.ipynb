{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mehrschichtiges Neuronales Netz in Tensorflow & Keras\n",
    "https://keras.io/\n",
    "![Image](./data/mnist2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Python Machine Learning API importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importieren der gesamten MNIST Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausgabe der Trainings- bzw. Testbilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausgabe der Shape (Form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# output the shape of the data (also was is drinnen in den datensätzen)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausgabe der Dimension des Arrays (Bilder) mit `.nidm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# output the dimension of the data\n",
    "print(train_images.ndim)\n",
    "print(test_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausgabe der Trainings-Indizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN erstellen\n",
    "\n",
    "generell benötigen wir hierfür:\n",
    "\n",
    "1. `Layer`\n",
    "\n",
    "2. `Eingabedaten` \n",
    "\n",
    "3. `Verlustfunktion`\n",
    "\n",
    "4. `Optimierer`\n",
    "\n",
    "![Image](./data/nn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Module (layers & models) importieren\n",
    "\n",
    "* Module: https://www.tensorflow.org/api_docs/python/tf/keras\n",
    "* z.B. models: https://www.tensorflow.org/api_docs/python/tf/keras/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisieren eines leeren Netzes\n",
    "#### mit dem Modul `models` bestimmen wir im folgenden einen linearen Stapel von Schichten `(Sequential)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer definieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Mit dem Argument `layers` definieren wir eine Liste von Layern, die dem Modell hinzugefügt werden sollen und legen die jewewiligen Attribute fest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) der input- und der hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(layers.Dense(512, activation='sigmoid', input_shape=(28 * 28,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `Dense` definiert einen layer in dem jeder Knoten mit jedem Knoten in der nachfolgenden verborgenen Schicht verbunden ist: `fully-connected Layer`\n",
    "+ `input_shape` = Input layer mit 784 Eingabewerten, in unserem Falle also ein 2-D-Tensor mit 28*28 Werten\n",
    "+ `activation` = Sigmoid-Aktivierungs-Funktion\n",
    "+ `512` = definiert die größe des hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) der output layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `10` (fully-connected) Knoten\n",
    "\n",
    "\n",
    "+ auf die die `softmax` funktion angewandt wird:\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### zum trainieren des Netzes benötigen wir noch weitere 3 Parameter :\n",
    "+ `loss` Verlustfunktion E = S-K https://keras.io/losses/ https://keras.io/backend/#categorical_crossentropy\n",
    "+ `optimizer` Gewichtsanpassung https://keras.io/optimizers/ https://keras.io/optimizers/#rmsprop\n",
    "+ `metrics`, definiert den Anteil der Bilder, die korrekt klassifiziert wurden https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainings- bzw. Testdaten vorbereiten, bzw. skalieren\n",
    "\n",
    "von [0-255] in einen Interval von [0, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n",
      "Datentyp before:  uint8\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 169 253 253 253 253\n",
      " 253 253 218  30   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  52 250 253 210  32\n",
      "  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31  18\n",
      "   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25 234 253 233\n",
      "  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  78 248 253\n",
      " 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 134 253\n",
      " 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147\n",
      "  10   0   0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253\n",
      " 168 143 166 253 253 253 253 253 253 253 123   0   0   0   0   0   0   0\n",
      "   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169\n",
      " 117 117  57   0   0   0   0   0   0   0   0   0   0 118 123 123 123 166\n",
      " 253 253 253 155 123 123  41   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "Datentyp after:  float32\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.45490196 0.49019608\n",
      " 0.67058825 1.         1.         0.5882353  0.3647059  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.6627451  0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.85490197 0.11764706 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.99215686\n",
      " 0.99215686 0.99215686 0.8352941  0.5568628  0.6901961  0.99215686\n",
      " 0.99215686 0.47843137 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20392157 0.98039216 0.99215686 0.8235294  0.1254902\n",
      " 0.04705882 0.         0.02352941 0.80784315 0.99215686 0.54901963\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3019608\n",
      " 0.9843137  0.8235294  0.09803922 0.         0.         0.\n",
      " 0.47843137 0.972549   0.99215686 0.25490198 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.12156863 0.07058824\n",
      " 0.         0.         0.         0.         0.81960785 0.99215686\n",
      " 0.99215686 0.25490198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.45882353 0.96862745 0.99215686 0.7764706  0.03921569\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29803923 0.96862745\n",
      " 0.99215686 0.90588236 0.24705882 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.5019608  0.99215686 0.99215686 0.5647059\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.6901961\n",
      " 0.9647059  0.99215686 0.62352943 0.04705882 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09803922 0.91764706 0.99215686 0.9137255\n",
      " 0.13725491 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.7764706  0.99215686 0.99215686 0.5529412  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.30588236 0.972549   0.99215686\n",
      " 0.7411765  0.04705882 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.07450981 0.78431374 0.99215686 0.99215686 0.5529412  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.5254902  0.99215686\n",
      " 0.99215686 0.6784314  0.04705882 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.972549   0.99215686 0.99215686 0.09803922\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.972549   0.99215686 0.99215686 0.16862746 0.07843138 0.07843138\n",
      " 0.07843138 0.07843138 0.01960784 0.         0.01960784 0.07843138\n",
      " 0.07843138 0.14509805 0.5882353  0.5882353  0.5882353  0.5764706\n",
      " 0.03921569 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.972549   0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.65882355 0.56078434 0.6509804  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.48235294 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.68235296 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.9764706  0.96862745 0.96862745 0.6627451\n",
      " 0.45882353 0.45882353 0.22352941 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.4627451  0.48235294 0.48235294 0.48235294 0.6509804\n",
      " 0.99215686 0.99215686 0.99215686 0.60784316 0.48235294 0.48235294\n",
      " 0.16078432 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "print(\"Label: \", test_labels[1])\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "print(\"Datentyp before: \", test_images.dtype)\n",
    "print(test_images[1])\n",
    "test_images = test_images.astype('float32') / 255\n",
    "print(\"Datentyp after: \", test_images.dtype)\n",
    "print(test_images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "##### Kodieren der Klassen (Ziffern) von 0 bis 9 - mit One-Hot-Kodierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel Label vor der Encodierung:  0\n",
      "Beispiel Label vor der Encodierung:  2\n",
      "Beilspiel Label nach der Encodierung:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Beispiel Label vor der Encodierung:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "print(\"Beispiel Label vor der Encodierung: \", train_labels[1])\n",
    "print(\"Beispiel Label vor der Encodierung: \", train_labels[5])\n",
    "train_labels = to_categorical(train_labels)\n",
    "print(\"Beilspiel Label nach der Encodierung: \", train_labels[1])\n",
    "print(\"Beispiel Label vor der Encodierung: \", train_labels[5])\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Netz trainieren\n",
    "+ `fit()` übergibt dem Modell (NN) die Numpy-Arrays der Eingabedaten `train_images` + Zielwerte `train_labels` \n",
    "+ `epochs` wie oft wir den gesamten Trainingssatz  durchlaufen möchten \n",
    "+ `batch_size`, Stapelgröße - wie viele Samples wir für eine Aktualisierung der Modellgewichte verwenden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4603 - accuracy: 0.8760\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2689 - accuracy: 0.9218\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2172 - accuracy: 0.9369\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1773 - accuracy: 0.9484\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1477 - accuracy: 0.9567\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1245 - accuracy: 0.9641\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1075 - accuracy: 0.9688\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0936 - accuracy: 0.9725\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0817 - accuracy: 0.9762\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0723 - accuracy: 0.9789\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0642 - accuracy: 0.9816\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0576 - accuracy: 0.9841\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0514 - accuracy: 0.9851\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0462 - accuracy: 0.9873\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0417 - accuracy: 0.9883\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0375 - accuracy: 0.9898\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0337 - accuracy: 0.9911\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0304 - accuracy: 0.9920\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9930\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0246 - accuracy: 0.9940\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 0.0611 - val_accuracy: 0.9802\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.0602 - val_accuracy: 0.9797\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.0586 - val_accuracy: 0.9807\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9802\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0629 - val_accuracy: 0.9808\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0598 - val_accuracy: 0.9805\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0600 - val_accuracy: 0.9815\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.0585 - val_accuracy: 0.9820\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0096 - accuracy: 0.9988 - val_loss: 0.0608 - val_accuracy: 0.9818\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.0616 - val_accuracy: 0.9806\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.0594 - val_accuracy: 0.9815\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0578 - val_accuracy: 0.9815\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0610 - val_accuracy: 0.9810\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0587 - val_accuracy: 0.9819\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.0602 - val_accuracy: 0.9822\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.0625 - val_accuracy: 0.9815\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0597 - val_accuracy: 0.9815\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0614 - val_accuracy: 0.9815\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0599 - val_accuracy: 0.9819\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0609 - val_accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "history=network.fit(train_images, train_labels, epochs=20, batch_size=128)\n",
    "history = network.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validierung durch Visualisierung des Trainingsdurchlaufs\n",
    "\n",
    "+ `loss` Verlustfunktion\n",
    "+ `acc` accuracy, Genauigkeit der Trainningsdaten, Korrektklassifizierungsrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# render the loss and validation loss\n",
    "#plt.plot(history.history['loss'], label='loss')\n",
    "#plt.plot(history.history['val_loss'], label='val_loss')\n",
    "#plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#print(\"Abnahme des Fehlers, bzw. Anstieg der Genauigkeit über die Epochen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9825\n",
      "test_loss (Verlustrate): 0.06090712919831276\n",
      "test_acc (Korrektklassifzierungsrate): 0.9825000166893005\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using the test data and print the accuracy\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_loss (Verlustrate):', test_loss)\n",
    "print('test_acc (Korrektklassifzierungsrate):', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f31da23abe0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the second image in the test data\n",
    "test_im = test_images[1]\n",
    "plt.imshow(test_im.reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[8.2482438e-11 1.6682121e-08 9.9999958e-01 2.0683094e-08 1.4776265e-16\n",
      " 1.6219235e-09 6.7379879e-09 1.8496983e-18 3.2358741e-07 3.1217357e-15]\n"
     ]
    }
   ],
   "source": [
    "# plott the second image in the test data with the predicted label\n",
    "predictions = network.predict(test_images)\n",
    "print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#print predicted label as integer\n",
    "print(np.argmax(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#print test label\n",
    "print(test_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plott the predicted img\n",
    "\n",
    "plt.imshow(test_im.reshape(28,28), cmap='Greys')\n",
    "plt.title(f\"Label: {test_labels[1]}\\nPredicted: {np.argmax(predictions[1])}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "network.save('mnist_trained_model.h5')  # creates a HDF5 file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
